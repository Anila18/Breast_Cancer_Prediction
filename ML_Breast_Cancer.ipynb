{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"D:\\\\UC_CS_COURSES\\\\ML\\\\Project\\\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"PREPROCESSING DATA\"\"\"\n",
    "data=data.fillna(0) #removing null values in data if exists\n",
    "data.drop(\"id\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#changing benign to 0 and malignant to 1\n",
    "data['diagnosis']=data['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # to apply the Logistic regression\n",
    "from sklearn.model_selection import train_test_split # to split the data into two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "#train on all features\n",
    "model.fit(train[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']],train['diagnosis'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#logistic regression model to predict on features\n",
    "predictions=model.predict(test[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Of Logistic Regression 0.964912280702\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the logistic regression model\n",
    "from sklearn import metrics\n",
    "Accuracy = metrics.accuracy_score(predictions,test['diagnosis'])\n",
    "print(\"Accuracy Of Logistic Regression\",Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Logistic Regression 0.938461538462\n"
     ]
    }
   ],
   "source": [
    "#Precision of the Logistic Regression model\n",
    "Precision = metrics.precision_score(predictions,test['diagnosis'])\n",
    "print(\"Precision of Logistic Regression\",Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of Logistic Regression 0.968253968254\n"
     ]
    }
   ],
   "source": [
    "#Recall of the Decision Trees model\n",
    "Recall = metrics.recall_score(predictions,test['diagnosis'])\n",
    "print(\"Recall of Logistic Regression\",Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 87.719%\n",
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 91.228%\n",
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 92.398%\n",
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 93.421%\n",
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 94.035%\n",
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 94.152%\n",
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 94.737%\n",
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 94.737%\n",
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 94.737%\n",
      "CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : 94.906%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "error=[]\n",
    "kfcv = cross_validation.KFold(data.shape[0], n_folds=10)\n",
    "for trainkfcv,testkfcv in kfcv:\n",
    "    x_train=data[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']].iloc[trainkfcv,:]\n",
    "    y_train=data['diagnosis'].iloc[trainkfcv]\n",
    "    model.fit(x_train,y_train)\n",
    "    x_test=data[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']].iloc[testkfcv,:]\n",
    "    y_test=data['diagnosis'].iloc[testkfcv]\n",
    "    error.append(model.score(x_test,y_test))\n",
    "    print(\"CROSS-VALIDATION ERROR FOR LOGISTIC REGRESSION : %s\" % \"{0:.3%}\".format(np.mean(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(criterion='entropy')\n",
    "#train on all features\n",
    "model.fit(train[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']],train['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions from Decision Tree Classifier\n",
    "predictions=model.predict(test[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Of Decision Trees 0.947368421053\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the Decision Trees model\n",
    "from sklearn import metrics\n",
    "Accuracy = metrics.accuracy_score(predictions,test['diagnosis'])\n",
    "print(\"Accuracy Of Decision Trees\",Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Decision Trees 0.876923076923\n"
     ]
    }
   ],
   "source": [
    "#Precision of the Decision Trees model\n",
    "Precision = metrics.precision_score(predictions,test['diagnosis'])\n",
    "print(\"Precision of Decision Trees\",Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of Decision Trees 0.98275862069\n"
     ]
    }
   ],
   "source": [
    "#Recall of the Decision Trees model\n",
    "Recall = metrics.recall_score(predictions,test['diagnosis'])\n",
    "print(\"Recall of Decision Trees\",Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 94.737%\n",
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 92.105%\n",
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 92.982%\n",
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 94.298%\n",
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 94.737%\n",
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 94.737%\n",
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 94.236%\n",
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 93.860%\n",
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 93.762%\n",
      "CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : 93.493%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "error=[]\n",
    "kfcv = cross_validation.KFold(data.shape[0], n_folds=10)\n",
    "for trainkfcv,testkfcv in kfcv:\n",
    "    x_train=data[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']].iloc[trainkfcv,:]\n",
    "    y_train=data['diagnosis'].iloc[trainkfcv]\n",
    "    model.fit(x_train,y_train)\n",
    "    x_test=data[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']].iloc[testkfcv,:]\n",
    "    y_test=data['diagnosis'].iloc[testkfcv]\n",
    "    error.append(model.score(x_test,y_test))\n",
    "    print(\"CROSS-VALIDATION ERROR FOR DECISION TREES MODEL : %s\" % \"{0:.3%}\".format(np.mean(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM model\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear',probability=True)\n",
    "model.fit(train[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']],train['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predictions from SVM Classifier\n",
    "predictions=model.predict(test[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Of SVM model 0.970760233918\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the SVM model\n",
    "from sklearn import metrics\n",
    "Accuracy = metrics.accuracy_score(predictions,test['diagnosis'])\n",
    "print(\"Accuracy Of SVM model\",Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of SVM model 0.953846153846\n"
     ]
    }
   ],
   "source": [
    "#Precision of the SVM model\n",
    "Precision = metrics.precision_score(predictions,test['diagnosis'])\n",
    "print(\"Precision of SVM model\",Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of SVM Model 0.96875\n"
     ]
    }
   ],
   "source": [
    "#Recall of the Decision Trees model\n",
    "Recall = metrics.recall_score(predictions,test['diagnosis'])\n",
    "print(\"Recall of SVM Model\",Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS-VALIDATION ERROR FOR SVM : 96.552%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 93.103%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 93.103%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 93.103%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 93.793%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 93.678%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 94.089%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 94.397%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 94.253%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 94.470%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 94.324%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 94.797%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 95.197%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 95.285%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 95.123%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 95.205%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 94.857%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 95.142%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 95.210%\n",
      "CROSS-VALIDATION ERROR FOR SVM : 95.271%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "error=[]\n",
    "kfcv = cross_validation.KFold(data.shape[0], n_folds=20)\n",
    "for trainkfcv,testkfcv in kfcv:\n",
    "    x_train=data[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']].iloc[trainkfcv,:]\n",
    "    y_train=data['diagnosis'].iloc[trainkfcv]\n",
    "    model.fit(x_train,y_train)\n",
    "    x_test=data[['radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']].iloc[testkfcv,:]\n",
    "    y_test=data['diagnosis'].iloc[testkfcv]\n",
    "    error.append(model.score(x_test,y_test))\n",
    "    print(\"CROSS-VALIDATION ERROR FOR SVM : %s\" % \"{0:.3%}\".format(np.mean(error)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
